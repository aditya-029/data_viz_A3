library(lubridate)
library(janitor)
# Path to the file
components_path <- "data/CPI, Goods and Services components, annual movement (%).csv"
# Read and clean
components_df <- read_csv(components_path, skip = 1) |>
clean_names() |>
rename(category = 1) |>
pivot_longer(
cols = -category,
names_to = "quarter",
values_to = "annual_change"
) |>
mutate(
quarter = str_replace_all(quarter, "_percent", ""),
quarter = str_replace_all(quarter, "_", "-"),
quarter = str_to_title(quarter),
quarter = parse_date(quarter, format = "%b-%y")
) |>
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(category, quarter)
# Preview structure
glimpse(components_df)
# Save cleaned version
write_csv(components_df, "data/goods_services_components_clean.csv")
View(components_df)
library(tidyverse)
library(lubridate)
library(janitor)
# Load the previously cleaned Group 1 data
group1_path <- "cleaned_data/group1_time_series_clean.csv"
group1_df <- read_csv(group1_path)
# Final cleaning and enhancement for storytelling
group1_final <- group1_df |>
# Ensure quarter is parsed as Date
mutate(quarter = as_date(quarter)) |>
# Filter for narrative window: Mar 2023 to Mar 2025
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
# Add temporal columns for faceting, plotting, labeling
mutate(
year = year(quarter),
quarter_num = quarter(quarter),
quarter_label = paste0("Q", quarter_num, " ", year)
) |>
# Fill any remaining missing numeric values (for visual smoothness)
fill(where(is.numeric), .direction = "downup") |>
# Reorder columns for clarity
select(
quarter, year, quarter_num, quarter_label,
rent_quarterly_change, rent_annual_change,
electricity_incl_rebate,
education_index,
cpi_quarterly_change, cpi_annual_change
) |>
# Arrange by chronological order
arrange(quarter)
# Optional: inspect the cleaned data
glimpse(group1_final)
# Save the final version
write_csv(group1_final, "cleaned_data/group1_time_series_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Define path to grocery data
grocery_path <- "data/Grocery products, annual movement (%).csv"
# Read and clean the grocery data
grocery_df <- read_csv(grocery_path, skip = 1) |>
clean_names() |>
rename(product = 1) |>
# Pivot wider columns (quarterly columns) into long format
pivot_longer(
cols = -product,
names_to = "quarter",
values_to = "annual_change"
) |>
# Format quarter (e.g., mar_24_percent -> Mar-2024)
mutate(
quarter = str_replace_all(quarter, "_percent", ""),
quarter = str_replace_all(quarter, "_", "-"),
quarter = str_to_title(quarter),
quarter = parse_date(quarter, format = "%b-%y")
) |>
# Filter for storytelling window
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(product, quarter)
# Optional: preview structure
glimpse(grocery_df)
# Save clean version
write_csv(grocery_df, "cleaned_data/grocery_annual_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Path to electricity index file
electricity_path <- "data/Electricity Index, Australia (June 2023 quarter = 100.0).csv"
# Read and clean the file
electricity_df <- read_csv(electricity_path, skip = 1) |>
clean_names() |>
rename(
quarter = 1,
excl_rebate_index = 2,
incl_rebate_index = 3
) |>
# Clean quarter format (e.g., "Jun-23" → Date)
mutate(
quarter = parse_date(quarter, format = "%b-%y")
) |>
# Filter for story window
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(quarter)
# Optional preview
glimpse(electricity_df)
# Save cleaned file
write_csv(electricity_df, "cleaned_data/electricity_index_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Path to education file
education_path <- "data/Education, Australia, March quarter movements (%).csv"
# Read the file (starts immediately with useful data)
education_df <- read_csv(education_path, skip = 1) |>
clean_names() |>
rename(quarter = 1) |>
# Pivot into long format if multiple education types (optional, based on structure)
pivot_longer(
cols = -quarter,
names_to = "education_type",
values_to = "quarterly_change"
) |>
# Parse the quarter (e.g., "Mar-23")
mutate(
quarter = parse_date(quarter, format = "%b-%y")
) |>
# Filter for our range
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(education_type, quarter)
# Optional: check data
glimpse(education_df)
# Save
write_csv(education_df, "cleaned_data/education_cpi_clean.csv")
View(education_df)
library(tidyverse)
library(lubridate)
library(janitor)
# Path to the file
components_path <- "data/CPI, Goods and Services components, annual movement (%).csv"
# Read and clean
components_df <- read_csv(components_path, skip = 1) |>
clean_names() |>
rename(category = 1) |>
pivot_longer(
cols = -category,
names_to = "quarter",
values_to = "annual_change"
) |>
mutate(
quarter = str_replace_all(quarter, "_percent", ""),
quarter = str_replace_all(quarter, "_", "-"),
quarter = str_to_title(quarter),
quarter = parse_date(quarter, format = "%b-%y")
) |>
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(category, quarter)
# Preview structure
glimpse(components_df)
# Save cleaned version
write_csv(components_df, "cleaned_data/goods_services_components_clean.csv")
View(components_df)
# Load required libraries
library(tidyverse)
library(lubridate)
library(janitor)
# Define path
rents_path <- "data/Rents, Australia, quarterly and annual movement (%).csv"
# Clean Rents data
rents_df <- read_csv(rents_path, skip = 1) |>
clean_names() |>
rename(
quarter_raw = 1,
quarterly_change = 2,
annual_change = 3
) |>
filter(!is.na(quarterly_change)) |>
mutate(
quarter = parse_date_time(quarter_raw, orders = "b-y"),  # e.g., Mar-24
quarter = as_date(quarter)
) |>
select(quarter, rent_quarterly_change = quarterly_change, rent_annual_change = annual_change)
electricity_path <- "data/Electricity Index, Australia (June 2023 quarter = 100.0).csv"
electricity_df <- read_csv(electricity_path, skip = 1) |>
clean_names() |>
rename(
quarter_raw = 1,
excl_rebate_index = 2,
incl_rebate_index = 3
) |>
filter(!is.na(incl_rebate_index)) |>
mutate(
quarter = parse_date_time(quarter_raw, orders = "b-y"),
quarter = as_date(quarter)
) |>
select(quarter, electricity_incl_rebate = incl_rebate_index)
education_path <- "data/Education, Australia, March quarter movements (%).csv"
education_df <- read_csv(education_path, skip = 1) |>
clean_names() |>
rename(
quarter_raw = 1,
education_index = 2
) |>
filter(!is.na(education_index)) |>
mutate(
quarter = parse_date_time(quarter_raw, orders = "b-y"),
quarter = as_date(quarter)
) |>
select(quarter, education_index)
cpi_path <- "data/All groups CPI, Australia, quarterly and annual movement (%).csv"
cpi_df <- read_csv(cpi_path, skip = 1) |>
clean_names() |>
rename(
quarter_raw = 1,
cpi_quarterly_change = 2,
cpi_annual_change = 3
) |>
filter(!is.na(cpi_quarterly_change)) |>
mutate(
quarter = parse_date_time(quarter_raw, orders = "b-y"),
quarter = as_date(quarter)
) |>
select(quarter, cpi_quarterly_change, cpi_annual_change)
# Reduce and merge all on 'quarter'
time_series_df <- list(rents_df, electricity_df, education_df, cpi_df) |>
reduce(full_join, by = "quarter") |>
arrange(quarter)
# View a preview
glimpse(time_series_df)
# Save the merged Group 1 dataset to a CSV file
write_csv(time_series_df, "/Users/adityarajbhoj/Desktop/UNI/Data_viz/Assignment_3/cost_of_living_as_students/cleaned_data/group1_time_series_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Load the previously cleaned Group 1 data
group1_path <- "cleaned_data/group1_time_series_clean.csv"
group1_df <- read_csv(group1_path)
# Final cleaning and enhancement for storytelling
group1_final <- group1_df |>
# Ensure quarter is parsed as Date
mutate(quarter = as_date(quarter)) |>
# Filter for narrative window: Mar 2023 to Mar 2025
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
# Add temporal columns for faceting, plotting, labeling
mutate(
year = year(quarter),
quarter_num = quarter(quarter),
quarter_label = paste0("Q", quarter_num, " ", year)
) |>
# Fill any remaining missing numeric values (for visual smoothness)
fill(where(is.numeric), .direction = "downup") |>
# Reorder columns for clarity
select(
quarter, year, quarter_num, quarter_label,
rent_quarterly_change, rent_annual_change,
electricity_incl_rebate,
education_index,
cpi_quarterly_change, cpi_annual_change
) |>
# Arrange by chronological order
arrange(quarter)
# Optional: inspect the cleaned data
glimpse(group1_final)
# Save the final version
write_csv(group1_final, "cleaned_data/group1_time_series_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Define path to grocery data
grocery_path <- "data/Grocery products, annual movement (%).csv"
# Read and clean the grocery data
grocery_df <- read_csv(grocery_path, skip = 1) |>
clean_names() |>
rename(product = 1) |>
# Pivot wider columns (quarterly columns) into long format
pivot_longer(
cols = -product,
names_to = "quarter",
values_to = "annual_change"
) |>
# Format quarter (e.g., mar_24_percent -> Mar-2024)
mutate(
quarter = str_replace_all(quarter, "_percent", ""),
quarter = str_replace_all(quarter, "_", "-"),
quarter = str_to_title(quarter),
quarter = parse_date(quarter, format = "%b-%y")
) |>
# Filter for storytelling window
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(product, quarter)
# Optional: preview structure
glimpse(grocery_df)
# Save clean version
write_csv(grocery_df, "cleaned_data/grocery_annual_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Path to electricity index file
electricity_path <- "data/Electricity Index, Australia (June 2023 quarter = 100.0).csv"
# Read and clean the file
electricity_df <- read_csv(electricity_path, skip = 1) |>
clean_names() |>
rename(
quarter = 1,
excl_rebate_index = 2,
incl_rebate_index = 3
) |>
# Clean quarter format (e.g., "Jun-23" → Date)
mutate(
quarter = parse_date(quarter, format = "%b-%y")
) |>
# Filter for story window
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(quarter)
# Optional preview
glimpse(electricity_df)
# Save cleaned file
write_csv(electricity_df, "cleaned_data/electricity_index_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Path to education file
education_path <- "data/Education, Australia, March quarter movements (%).csv"
# Read the file (starts immediately with useful data)
education_df <- read_csv(education_path, skip = 1) |>
clean_names() |>
rename(quarter = 1) |>
# Pivot into long format if multiple education types (optional, based on structure)
pivot_longer(
cols = -quarter,
names_to = "education_type",
values_to = "quarterly_change"
) |>
# Parse the quarter (e.g., "Mar-23")
mutate(
quarter = parse_date(quarter, format = "%b-%y")
) |>
# Filter for our range
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(education_type, quarter)
# Optional: check data
glimpse(education_df)
# Save
write_csv(education_df, "cleaned_data/education_cpi_clean.csv")
library(tidyverse)
library(lubridate)
library(janitor)
# Path to the file
components_path <- "data/CPI, Goods and Services components, annual movement (%).csv"
# Read and clean
components_df <- read_csv(components_path, skip = 1) |>
clean_names() |>
rename(category = 1) |>
pivot_longer(
cols = -category,
names_to = "quarter",
values_to = "annual_change"
) |>
mutate(
quarter = str_replace_all(quarter, "_percent", ""),
quarter = str_replace_all(quarter, "_", "-"),
quarter = str_to_title(quarter),
quarter = parse_date(quarter, format = "%b-%y")
) |>
filter(quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")) |>
arrange(category, quarter)
# Preview structure
glimpse(components_df)
# Save cleaned version
write_csv(components_df, "cleaned_data/goods_services_components_clean.csv")
View(components_df)
# Step 1: Load raw file without cleaning
raw_components <- read_csv("data/CPI, Goods and Services components, annual movement (%).csv", show_col_types = FALSE)
# Step 2: View first rows
head(raw_components)
# Step 3: Inspect column names
colnames(raw_components)
library(readr)
# Read raw lines
lines <- read_lines("data/CPI, Goods and Services components, annual movement (%).csv")
# View the first few lines
cat(lines[1:6], sep = "\n")
library(tidyverse)
library(lubridate)
# File path
components_path <- "data/CPI, Goods and Services components, annual movement (%).csv"
# Read the actual data, skipping the title line
components_clean <- read_csv(
file = components_path,
skip = 1,             # Skip the metadata line
col_names = TRUE,     # Use the second line as header
show_col_types = FALSE
) |>
rename(
quarter = 1,
goods_annual = 2,
services_annual = 3
) |>
mutate(
# Convert "Mar-15" → Date format
quarter = parse_date(quarter, format = "%b-%y")
) |>
filter(
quarter >= as_date("2023-03-01") & quarter <= as_date("2025-03-01")
)
# Save the cleaned data
write_csv(components_clean, "data/goods_services_components_clean.csv")
# Print a preview
print(components_clean)
library(tidyverse)
library(lubridate)
# Load cleaned files
electricity <- read_csv("cleaned_data/electricity_index_clean.csv", show_col_types = FALSE)
goods_services <- read_csvcleaned_data
library(tidyverse)
library(lubridate)
# Load cleaned files
electricity <- read_csv("cleaned_data/electricity_index_clean.csv", show_col_types = FALSE)
goods_services <- read_csv("cleaned_data/goods_services_components_clean.csv", show_col_types = FALSE)
education <- read_csv("cleaned_data/education_cpi_clean.csv", show_col_types = FALSE)
grocery <- read_csv("cleaned_data/grocery_annual_clean.csv", show_col_types = FALSE)
# Merge electricity and goods/services
group2_base <- left_join(electricity, goods_services, by = "quarter")
# Save base merge
write_csv(group2_base, "cleaned_data/group2_base_clean.csv")
# Optionally, save others separately
write_csv(education, "cleaned_data/group2_education_clean.csv")
write_csv(grocery, "cleaned_data/group2_grocery_clean.csv")
shiny::runApp()
clea
clear
getwd()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
colnames(readr::read_csv("cleaned_data/group1_time_series_clean.csv"))
colnames(readr::read_csv("cleaned_data/group1_time_series_clean.csv"))
colnames(readr::read_csv("cleaned_data/group1_time_series_clean.csv"))
shiny::runApp()
group1_data %>% select(quarter, starts_with("grocery"))
group1_data %>% select(quarter, starts_with("grocery"))
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj',
token='A6857804FE2955663F7E261142D5AE9F',
secret='iq0v9ZSOXnarBGA9ujp4UMkpFoBtM6xBKz5lGYDZ')
runApp()
install.packages("rsconnect")
install.packages("rsconnect")
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj', token='9D7B873D8CB3520FE3CE7A08EA6BD209', secret='302mzLdhVEymYEfIhnsNziZTFvpgwm3acZrcmh7P')
install.packages("curl", dependencies = TRUE)
install.packages("httr", dependencies = TRUE)
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj', token='9D7B873D8CB3520FE3CE7A08EA6BD209', secret='302mzLdhVEymYEfIhnsNziZTFvpgwm3acZrcmh7P')
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj', token='9D7B873D8CB3520FE3CE7A08EA6BD209', secret='302mzLdhVEymYEfIhnsNziZTFvpgwm3acZrcmh7P')
unlink("~/.rsconnect", recursive = TRUE)
rsconnect::setAccountInfo(
name = "ylmgdd-aditya-rajbhoj",
token = "9D7B873D8CB3520FE3CE7A08EA6BD209",
secret = "302mzLdhVEymYEfIhnsNziZTFvpgwm3acZrcmh7P"
)
install.packages("curl")
install.packages("httr")
install.packages("rsconnect")
install.packages("curl")
install.packages("httr")
install.packages("rsconnect")
httr::set_config(httr::config(ssl_verifypeer = 0))
rsconnect::setAccountInfo(
name = "ylmgdd-aditya-rajbhoj",
token = "9D7B873D8CB3520FE3CE7A08EA6BD209",
secret = "302mzLdhVEymYEfIhnsNziZTFvpgwm3acZrcmh7P"
)
install.packages('rsconnect')
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj', token='0D0BA8CFE4944C9F76199F0B2589E989', secret='gpj92xh/vTSpwp1lGYzTRvZL3cHxh+Xxg/8p2wNh')
rsconnect::setAccountInfo
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj', token='0D0BA8CFE4944C9F76199F0B2589E989', secret='gpj92xh/vTSpwp1lGYzTRvZL3cHxh+Xxg/8p2wNh')
shiny::runApp()
rsconnect::setAccountInfo(name='ylmgdd-aditya-rajbhoj',token='0D0BA8CFE4944C9F76199F0B2589E989',secret='gpj92xh/vTSpwp1lGYzTRvZL3cHxh+Xxg/8p2wNh')
install.packages(c("curl", "httr"))
install.packages(c("curl", "httr"))
rsconnect::setAccountInfo(name='aditya-rajbhoj-data-viz', token='1E0152CE5EFEFFC3B42FF0501B8ADA4B', secret='tFz23nwALgU+IjtQuc90on7Ry+6RDnTj5tYniCzw')
install.packages("curl", type = "source")
install.packages("httr", type = "source")
rsconnect::setAccountInfo(name='aditya-rajbhoj-data-viz', token='1E0152CE5EFEFFC3B42FF0501B8ADA4B', secret='tFz23nwALgU+IjtQuc90on7Ry+6RDnTj5tYniCzw')
.rs.restartR()  # This restarts R cleanly inside RStudio
rsconnect::setAccountInfo(name='aditya-rajbhoj-data-viz', token='1E0152CE5EFEFFC3B42FF0501B8ADA4B', secret='tFz23nwALgU+IjtQuc90on7Ry+6RDnTj5tYniCzw')
rsconnect::accounts()  # List existing accounts
rsconnect::removeAccount("aditya-rajbhoj-data-viz")
rsconnect::accounts()
